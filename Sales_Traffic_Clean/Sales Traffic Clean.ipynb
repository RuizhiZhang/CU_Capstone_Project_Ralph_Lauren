{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Seasonal Pattern Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "from datetime import datetime\n",
    "\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'G'\n",
    "## Facebook Prophet\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sales_data(input_file_path, output_file_path):\n",
    "    #read_file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    df_additional_holidays = pd.read_csv('helper_table_holidays.csv')\n",
    "    # convert to date type\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d'))\n",
    "    # extract only the date and sales\n",
    "    df[[\"ds\", \"y\"]] = df[[\"date\", \"sales_retail\"]].rename(columns={\"date\": \"ds\", \"sales_retail\": \"y\"})\n",
    "    # df[[\"ds\", \"y\"]] = df[[\"date\", \"traffic\"]].rename(columns={\"date\": \"ds\", \"traffic\": \"y\"})\n",
    "    df_sub = df[[\"ds\", \"y\"]]\n",
    "    # build and train prophet model\n",
    "    m = Prophet(holidays = df_additional_holidays)\n",
    "    m.add_country_holidays(country_name='US')\n",
    "    m.fit(df_sub)\n",
    "    # forecast\n",
    "    future = m.make_future_dataframe(periods=1)\n",
    "    forecast = m.predict(future)\n",
    "    # remove the \"_upper\" and \"\"\n",
    "    upper_pattern_ls = list(forecast.filter(regex='_upper'))\n",
    "    lower_pattern_ls = list(forecast.filter(regex='_lower'))\n",
    "    forecast_ls = list(forecast.columns)\n",
    "    # remove\n",
    "    for pattern in upper_pattern_ls:\n",
    "        forecast_ls.remove(pattern)\n",
    "    for pattern in lower_pattern_ls:\n",
    "        forecast_ls.remove(pattern)\n",
    "    # get df with \"_upper\" & \"_lower\" column been removed\n",
    "    df_remove = forecast.loc[:,forecast_ls] \n",
    "    #forecast_ls\n",
    "    # get the pattern sum\n",
    "    sum_ls = forecast_ls\n",
    "    for col in ['ds','multiplicative_terms','yhat','additive_terms','holidays']:\n",
    "        sum_ls.remove(col)\n",
    "    df_remove['Pattern Sum'] = df_remove[sum_ls].sum(axis=1)\n",
    "    #merge df and df_remove\n",
    "    df_merge = pd.merge(df, df_remove[['ds','trend','holidays','weekly','yearly','Pattern Sum']], left_on='date', right_on='ds', how='left')\n",
    "\n",
    "    df_merge['sales_cleaned'] = df_merge['sales_retail'] - df_merge['Pattern Sum']\n",
    "    df_merge = df_merge[['date', 'sales_retail','sales_cleaned','trend','holidays','weekly','yearly']]\n",
    "    df_merge.rename(columns={\"sales_retail\": \"sales_original\"}, inplace = True)\n",
    "\n",
    "    # df_merge['traffic_cleaned'] = df_merge['traffic'] - df_merge['Pattern Sum']\n",
    "    # df_merge = df_merge[['date', 'traffic','traffic_cleaned','trend','holidays','weekly','yearly']]\n",
    "    # df_merge.rename(columns={\"traffic\": \"traffic_original\"}, inplace = True)\n",
    "    df_merge.to_csv(path_or_buf=output_file_path, index = False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales_cleaned Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"salea_traffic_cleaned_for_pattern_removal/1208_Orlando_FOA_sales_traffic_data.csv\"\n",
    "output_file_path = '/Users/yawenhan/Desktop/1208_Orlando_FOA_FOA_sales_cleaned.csv'\n",
    "clean_sales_data(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_traffic_data(input_file_path, output_file_path):\n",
    "    #read_file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    df_additional_holidays = pd.read_csv('helper_table_holidays.csv')\n",
    "    # convert to date type\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d'))\n",
    "    # extract only the date and sales\n",
    "    #df[[\"ds\", \"y\"]] = df[[\"date\", \"sales_retail\"]].rename(columns={\"date\": \"ds\", \"sales_retail\": \"y\"})\n",
    "    df[[\"ds\", \"y\"]] = df[[\"date\", \"traffic\"]].rename(columns={\"date\": \"ds\", \"traffic\": \"y\"})\n",
    "    df_sub = df[[\"ds\", \"y\"]]\n",
    "    # build and train prophet model\n",
    "    m = Prophet(holidays = df_additional_holidays)\n",
    "    m.add_country_holidays(country_name='US')\n",
    "    m.fit(df_sub)\n",
    "    # forecast\n",
    "    future = m.make_future_dataframe(periods=1)\n",
    "    forecast = m.predict(future)\n",
    "    # remove the \"_upper\" and \"\"\n",
    "    upper_pattern_ls = list(forecast.filter(regex='_upper'))\n",
    "    lower_pattern_ls = list(forecast.filter(regex='_lower'))\n",
    "    forecast_ls = list(forecast.columns)\n",
    "    # remove\n",
    "    for pattern in upper_pattern_ls:\n",
    "        forecast_ls.remove(pattern)\n",
    "    for pattern in lower_pattern_ls:\n",
    "        forecast_ls.remove(pattern)\n",
    "    # get df with \"_upper\" & \"_lower\" column been removed\n",
    "    df_remove = forecast.loc[:,forecast_ls] \n",
    "    #forecast_ls\n",
    "    # get the pattern sum\n",
    "    sum_ls = forecast_ls\n",
    "    for col in ['ds','multiplicative_terms','yhat','additive_terms','holidays']:\n",
    "        sum_ls.remove(col)\n",
    "    df_remove['Pattern Sum'] = df_remove[sum_ls].sum(axis=1)\n",
    "    #merge df and df_remove\n",
    "    df_merge = pd.merge(df, df_remove[['ds','trend','holidays','weekly','yearly','Pattern Sum']], left_on='date', right_on='ds', how='left')\n",
    "\n",
    "#     df_merge['sales_cleaned'] = df_merge['sales_retail'] - df_merge['Pattern Sum']\n",
    "#     df_merge = df_merge[['date', 'sales_retail','sales_cleaned','trend','holidays','weekly','yearly']]\n",
    "#     df_merge.rename(columns={\"sales_retail\": \"sales_original\"}, inplace = True)\n",
    "\n",
    "    df_merge['traffic_cleaned'] = df_merge['traffic'] - df_merge['Pattern Sum']\n",
    "    df_merge = df_merge[['date', 'traffic','traffic_cleaned','trend','holidays','weekly','yearly']]\n",
    "    df_merge.rename(columns={\"traffic\": \"traffic_original\"}, inplace = True)\n",
    "    df_merge.to_csv(path_or_buf=output_file_path, index = False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic_cleaned Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"salea_traffic_cleaned_for_pattern_removal/1208_Orlando_FOA_sales_traffic_data.csv\"\n",
    "output_file_path = '/Users/yawenhan/Desktop/1208_Orlando_FOA_traffic_cleaned.csv'\n",
    "clean_traffic_data(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
